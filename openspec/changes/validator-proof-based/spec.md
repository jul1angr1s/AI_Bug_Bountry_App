# Validator Agent (Proof-Based) Specification

## Overview

This specification defines the Validator Agent that uses Kimi 2.5 LLM to analyze exploit proofs generated by the Researcher Agent and validate their correctness before triggering bounty payments.

## Technical Specification

### ADDED Requirements

### Requirement: System SHALL validate exploit proofs using LLM analysis
The system SHALL use Kimi 2.5 LLM to analyze exploit proof-of-concept code and determine if it demonstrates a valid vulnerability.

#### Scenario: Validator Agent picks up validation job
- **GIVEN** Finding record exists with status=PENDING_VALIDATION and proof field populated
- **WHEN** Validator Agent worker processes validation queue job
- **THEN** system SHALL fetch Finding record by ID
- **THEN** system SHALL extract proof code from Finding.proof field

#### Scenario: LLM analyzes exploit proof logic
- **GIVEN** proof code is available
- **WHEN** Validator Agent sends proof to Kimi 2.5 API
- **THEN** system SHALL construct prompt with template:
  ```
  Validate this exploit proof for a Solidity smart contract vulnerability.

  Contract Code:
  {contract_source_code}

  Vulnerability Description:
  {finding_description}

  Exploit Proof-of-Concept:
  {proof_code}

  Analysis Instructions:
  1. Review the proof logic step-by-step
  2. Verify the proof demonstrates the described vulnerability
  3. Check if the exploit is realistic and executable
  4. Evaluate the severity of the vulnerability
  5. Calculate confidence level (0-100%)

  Response Format:
  - Valid: [YES/NO]
  - Confidence: [0-100]%
  - Reasoning: [Detailed explanation]
  ```
- **THEN** system SHALL send prompt to Kimi 2.5 API with model="k1.5-all"
- **THEN** system SHALL wait for LLM response with timeout of 60 seconds

#### Scenario: LLM validates oracle manipulation vulnerability
- **GIVEN** proof demonstrates oracle manipulation in Thunder Loan protocol
- **WHEN** LLM analyzes proof code
- **THEN** LLM response SHALL indicate Valid=YES
- **THEN** LLM SHALL calculate confidence score ≥85%
- **THEN** LLM SHALL explain reasoning: "The proof successfully manipulates the fee calculation by exploiting the oracle price feed timing window"

#### Scenario: LLM rejects invalid proof
- **GIVEN** proof does not demonstrate actual vulnerability
- **WHEN** LLM analyzes proof code
- **THEN** LLM response SHALL indicate Valid=NO
- **THEN** LLM SHALL calculate confidence score for invalidity
- **THEN** LLM SHALL explain reasoning: "The proof does not exploit any vulnerability; it merely calls public functions within normal parameters"

### Requirement: System SHALL parse LLM response and update Finding record
The system SHALL extract validation verdict and confidence score from LLM response and update database.

#### Scenario: Parse successful validation response
- **GIVEN** LLM returns Valid=YES with confidence=95%
- **WHEN** Validator Agent parses response
- **THEN** system SHALL extract confidence score as integer (95)
- **THEN** system SHALL extract reasoning text
- **THEN** system SHALL update Finding record:
  - status = VALIDATED
  - validatedAt = current timestamp
  - confidence = 95
  - validationLogs = LLM reasoning text

#### Scenario: Parse rejection response
- **GIVEN** LLM returns Valid=NO
- **WHEN** Validator Agent parses response
- **THEN** system SHALL update Finding record:
  - status = INVALID
  - validatedAt = current timestamp
  - confidence = 0
  - validationLogs = LLM reasoning text
- **THEN** system SHALL NOT trigger payment queue

### Requirement: System SHALL trigger payment queue on successful validation
The system SHALL automatically queue payment processing when proof is validated with sufficient confidence.

#### Scenario: Validated finding triggers payment
- **GIVEN** Finding updated to status=VALIDATED with confidence ≥80%
- **WHEN** validation completes successfully
- **THEN** system SHALL create Payment record:
  - findingId = validated Finding ID
  - researcherAddress = Finding.researcherAddress
  - amount = calculated bounty amount based on severity
  - currency = "USDC"
  - status = PENDING
- **THEN** system SHALL add job to payment queue with payload { paymentId, findingId }
- **THEN** system SHALL broadcast WebSocket event `validation:complete` with { findingId, status: "VALIDATED", confidence }

#### Scenario: Low confidence validation does not trigger payment
- **GIVEN** LLM returns Valid=YES but confidence <80%
- **WHEN** validation completes
- **THEN** system SHALL update Finding to status=MANUAL_REVIEW
- **THEN** system SHALL NOT create Payment record
- **THEN** system SHALL broadcast WebSocket event `validation:manual_review_required`

### Requirement: System SHALL handle validation errors with retry logic
The system SHALL gracefully handle API failures, timeouts, and parsing errors with exponential backoff retry.

#### Scenario: Kimi API request fails with network error
- **GIVEN** Kimi API is unreachable (ECONNREFUSED)
- **WHEN** Validator Agent attempts validation
- **THEN** system SHALL catch error and log: "Kimi API connection failed"
- **THEN** system SHALL throw error to trigger BullMQ retry
- **THEN** system SHALL retry job with exponential backoff (1m, 2m, 4m)
- **THEN** after 3 failed retries, system SHALL move job to dead letter queue

#### Scenario: Kimi API timeout
- **GIVEN** Kimi API response exceeds 60 second timeout
- **WHEN** Validator Agent waits for response
- **THEN** system SHALL abort request and throw timeout error
- **THEN** system SHALL retry job up to 3 times
- **THEN** system SHALL log: "Validation timeout for findingId={id}"

#### Scenario: LLM response parsing error
- **GIVEN** LLM returns malformed response (missing "Valid" field)
- **WHEN** Validator Agent parses response
- **THEN** system SHALL catch parsing error
- **THEN** system SHALL log: "Failed to parse LLM response: {error}"
- **THEN** system SHALL retry job with same exponential backoff
- **THEN** after 3 retries, system SHALL update Finding.status = VALIDATION_FAILED

### Requirement: System SHALL run validation worker on server startup
The system SHALL initialize Validator Agent worker process when backend server starts.

#### Scenario: Server starts validation worker
- **GIVEN** backend server is starting up
- **WHEN** server initialization runs
- **THEN** system SHALL create BullMQ Worker instance for "validation" queue
- **THEN** system SHALL register validation job processor function
- **THEN** system SHALL set concurrency to 3 (process 3 validations in parallel)
- **THEN** system SHALL connect to Redis queue
- **THEN** system SHALL log: "Validator Agent worker started"

#### Scenario: Worker processes multiple validations concurrently
- **GIVEN** 5 validation jobs in queue
- **WHEN** Validator Agent worker is running with concurrency=3
- **THEN** system SHALL process 3 validations simultaneously
- **THEN** system SHALL process remaining 2 after first batch completes

### Requirement: System SHALL expose validation API endpoints
The system SHALL provide REST API for fetching validation history and statistics.

#### Scenario: Fetch all validations with pagination
- **WHEN** client requests GET `/api/v1/validations?page=1&limit=20`
- **THEN** system SHALL query Finding records with status IN (VALIDATED, INVALID, VALIDATION_FAILED)
- **THEN** system SHALL return JSON with array of validations including: findingId, protocolName, status, confidence, validatedAt, validationLogs
- **THEN** response SHALL include pagination metadata

#### Scenario: Fetch validation by finding ID
- **WHEN** client requests GET `/api/v1/validations/:findingId`
- **THEN** system SHALL return validation details including full proof code and LLM reasoning
- **THEN** response SHALL include related Finding and Protocol data

#### Scenario: Filter validations by protocol
- **WHEN** client requests GET `/api/v1/validations?protocolId={id}`
- **THEN** system SHALL return only validations for specified protocol

#### Scenario: Filter validations by status
- **WHEN** client requests GET `/api/v1/validations?status=VALIDATED`
- **THEN** system SHALL return only validations with matching status

## Implementation Notes

### Technology Stack
- **Queue**: BullMQ with Redis backend
- **LLM**: Moonshot AI Kimi 2.5 API (model: k1.5-all)
- **Worker**: Node.js worker process with concurrency=3
- **Database**: PostgreSQL with Prisma ORM

### Validation Service Architecture
```typescript
// backend/src/services/validation.service.ts
export class ValidationService {
  async validateProof(findingId: string): Promise<ValidationResult> {
    // 1. Fetch Finding record with proof
    // 2. Construct LLM prompt
    // 3. Call Kimi API
    // 4. Parse response
    // 5. Update Finding record
    // 6. Trigger payment queue if valid
    // 7. Broadcast WebSocket event
  }

  async parseLLMResponse(response: string): Promise<{
    valid: boolean;
    confidence: number;
    reasoning: string;
  }> {
    // Parse structured LLM response
  }

  async triggerPayment(findingId: string): Promise<void> {
    // Create Payment record and queue job
  }
}
```

### BullMQ Queue Configuration
```typescript
// backend/src/queues/validation.queue.ts
export const validationQueue = new Queue('validation', {
  connection: redis,
  defaultJobOptions: {
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 60000, // 1 minute
    },
    removeOnComplete: 1000,
    removeOnFail: 5000,
  },
});

export const validationWorker = new Worker('validation', async (job) => {
  const { findingId } = job.data;
  return await validationService.validateProof(findingId);
}, {
  connection: redis,
  concurrency: 3,
});
```

### Prompt Engineering Strategy
The validation prompt is engineered to:
1. Provide full contract context
2. Provide vulnerability description from Researcher Agent
3. Include exploit proof code
4. Request structured response (Valid, Confidence, Reasoning)
5. Emphasize step-by-step analysis

### Confidence Threshold Logic
- **≥80% confidence**: Auto-approve and trigger payment
- **50-79% confidence**: Flag for manual review
- **<50% confidence**: Auto-reject as invalid

### Error Handling Strategy
- **Network errors**: Retry with exponential backoff
- **Timeouts**: Retry up to 3 times, then DLQ
- **Parse errors**: Retry with backoff, then mark VALIDATION_FAILED
- **API rate limits**: Respect rate limit headers, delay retries

## Success Criteria

- [ ] Validator Agent processes validation jobs from queue
- [ ] Kimi 2.5 LLM analyzes proof code successfully
- [ ] Confidence scores calculated accurately (0-100%)
- [ ] Validated findings trigger payment queue automatically
- [ ] Invalid findings do not trigger payments
- [ ] Retry logic handles transient failures
- [ ] Dead letter queue captures permanent failures
- [ ] WebSocket events broadcast validation status in real-time
- [ ] Validation API endpoints return paginated results
- [ ] Worker runs with concurrency=3 for parallel processing
